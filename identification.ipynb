{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-identification/De-identification \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Read a configuration file containing column labels in csv. Strings are quasi-identifiers. \n",
    "\"\"\"\n",
    "def read_config(config_file):\n",
    "    with open(config_file) as file:\n",
    "        identifiers = [(q) for q in file.read().split()]\n",
    "    file.close()\n",
    "    return sorted(identifiers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many entries contain NaN where the user did not enter information. Fill these values with 0 in order to filter them during analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NA_FILL_VALUE = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv(\"mid_sample_set.csv\", dtype='unicode')\n",
    "# Set user id as index\n",
    "df_raw.index = df_raw.user_id\n",
    "df_raw = df_raw.drop('user_id', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NA columns\n",
    "original_columns = set(df_raw.columns.values)\n",
    "df = df_raw.dropna(axis = 1, how = 'all').fillna(NA_FILL_VALUE)\n",
    "new_columns = set(df.columns.values)\n",
    "print(\"Removed columns\", original_columns - new_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon loading the dataset, there are 200,000 entries (users) and 87 fields (identifiers) for each row entry."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Direct Identifiers\n",
    "- Can uniquely identify an individual and should be removed\n",
    "- This includes ip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('ip', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasi-Identifiers\n",
    "- Can uniquely identify an individual when linked to other datasets. \n",
    "- These include: 'user_id', 'countryLabel', 'continent', 'city', 'region', 'subdivision', 'postalCode', 'LoE', 'YoB', 'gender', 'nforum_posts', 'nforum_votes', 'nforum_endorsed', 'nforum_threads', 'nforum_comments', 'nforum_pinned', and 'nforum_events', and are listed as their corresponding column index in the configuration file.\n",
    "- Redundant quasi-identifiers are not included \n",
    "- course_id was dropped \n",
    "- Create a version of the dataset that only contains the quasi-identifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quasi_identifiers = read_config(\"config_file.txt\")\n",
    "df_quasi = df.loc[:,quasi_identifiers]\n",
    "labels = list(df_quasi.columns.values)\n",
    "# Remove user_id because it's not a quasi-identifier, just a key\n",
    "quasi_identifier_labels = list(set(labels) - set([\"user_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Suppresses groups that Calculates the percentage of students who completed the course. Inputs are the dataframe,\n",
    "quasi-identifiers and level of k-anonmity \n",
    "\"\"\"\n",
    "def getAnonCompletionRates(df, quasi_identifier_labels, k):\n",
    "    if 'course_id' not in quasi_identifier_labels:\n",
    "        quasi_identifier_labels.append('course_id')\n",
    "    # Creates groupings of quasi identifiers and finds size of each set\n",
    "    k_anonymous = df.groupby(quasi_identifier_labels)\\\n",
    "                  .size().reset_index(name = 'ct').set_index(quasi_identifier_labels)\n",
    "    k_anonymous = k_anonymous[k_anonymous.ct >= k]\n",
    "    \n",
    "    # Add completion status for each student \n",
    "    completedCount = df.groupby(quasi_identifier_labels + ['completed'])\\\n",
    "                       .size()\\\n",
    "                       .reset_index(name = \"completedCount\")\\\n",
    "                       .set_index(quasi_identifier_labels)\n",
    "                \n",
    "    # Find size of altered dataset after k-anonymization \n",
    "    k_anonymous = k_anonymous.reset_index()\\\n",
    "                  .merge(completedCount[completedCount.completed == 'True'].reset_index(), how = \"left\")\n",
    "        \n",
    "    print(\"Size of %d-anonymous dataset: %d\" % (k, k_anonymous.ct.sum()))\n",
    "    \n",
    "    # Aggregate statuses and find overall completion rate \n",
    "    k_AnonTotalCounts = k_anonymous.groupby('course_id')[\"ct\"].sum()\\\n",
    "                                   .reset_index(name = \"numStudents\")\\\n",
    "                                   .set_index('course_id')\n",
    "    \n",
    "    completionRates = ((k_anonymous.set_index('course_id').completedCount.fillna(0)\n",
    "                        / k_AnonTotalCounts.numStudents).fillna(0) * 100)\\\n",
    "                        .reset_index(name = \"completionRate\")\\\n",
    "                        .sort_values(by = \"completionRate\", ascending = False)\n",
    "    \n",
    "    if len(k_anonymous) == 0: \n",
    "        completionRates.completionRate = 0\n",
    "    \n",
    "    return completionRates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate3Anon = getAnonCompletionRates(df, quasi_identifier_labels, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate3Anon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate4Anon = getAnonCompletionRates(df, quasi_identifier_labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate4Anon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate5Anon = getAnonCompletionRates(df, quasi_identifier_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate5Anon.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Records\n",
    "- Make the data k-anonymous\n",
    "- Find the number of synthetic records needed for each case\n",
    "- Compute completion rates and compare to dataset without synthetic records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adds artifical rows of data in order to acheive desired k-anonmity level. \n",
    "Each synthetic row is a duplicate of row data that is not yet k-anonymous.\n",
    "\"\"\"\n",
    "def addSyntheticRows(df, quasi_identifier_labels, k):\n",
    "    synthetic_k_anon_df = df.reset_index()\n",
    "    # Create groupings based on quasi identifiers and count number of students in each group\n",
    "    not_k_anonymous = synthetic_k_anon_df.groupby(quasi_identifier_labels)\\\n",
    "                      .size().reset_index(name = 'studentCount')\n",
    "        \n",
    "    # Assign groupings where studentCount is less than desired level for k-anonymity \n",
    "    not_k_anonymous = not_k_anonymous[not_k_anonymous.studentCount < k]\n",
    "\n",
    "    # Duplicate rows where groupings of quasi-identifiers are not k-anonymous\n",
    "    for i in range(k):\n",
    "        rowsToAdd = not_k_anonymous[not_k_anonymous.studentCount == i]\n",
    "        if len(rowsToAdd) > 0:\n",
    "            for j in range(k - i):\n",
    "                synthetic_k_anon_df = synthetic_k_anon_df.append(rowsToAdd, ignore_index = True)\n",
    "            \n",
    "    # Calculate difference between dataset and k-anonymized dataset with synthetic rows\n",
    "    rowsAdded = synthetic_k_anon_df.shape[0] - len(df)\n",
    "    print(\"Size of synthetic dataset: %d\\nSynthetic Rows Added: %d\" % (len(synthetic_k_anon_df), rowsAdded))\n",
    "    # Drop the studentCount column from the dataset we return because df_quasi does not\n",
    "    # have it.  This column is an artifact of when we grouped synthetic_k_anon_df above\n",
    "    synthetic_k_anon_df = synthetic_k_anon_df.drop(\"studentCount\", axis = 1)\n",
    "    return synthetic_k_anon_df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add synthetic data when k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic3AnonDf = addSyntheticRows(df, quasi_identifier_labels, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add synthetic data when k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic4AnonDf = addSyntheticRows(df, quasi_identifier_labels, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add synthetic data when k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic5AnonDf = addSyntheticRows(df, quasi_identifier_labels, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Anonymity \n",
    "- Generalization\n",
    "    - YoB, nform_* \n",
    "- Blurring\n",
    "    - Last 3 digits of postal_code\n",
    "- Suprression \n",
    "    - Remaining \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df_quasi_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blurring(df, col, lenCol):\n",
    "    df_quasi_blur = df\n",
    "    # Blurr the last 3 elements of string with stars\n",
    "    df_quasi_blur.loc[:,col] = df_quasi_blur.loc[:,col].astype(str).str[0:int(lenCol-3)] + \"*\" * 3;\n",
    "    return df_quasi_blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blurring(df_quasi_copy, \"postalCode\", 5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalization(df, colChange, bucketSize, maxVal):\n",
    "    col = colChange\n",
    "    df_quasi_gen = df\n",
    "    # Calculate number of categories with maximum value in column and size of each category interval \n",
    "    binNum = int(maxVal / bucketSize)\n",
    "    # Create list of categories \n",
    "    bins = [bucketSize*i for i in range(NA_FILL_VALUE-1, binNum)]\n",
    "    # Convert data to integers and assign each value to specified list of categories \n",
    "    df_quasi_gen.loc[:,col] = df_quasi_gen[col].astype(int)\n",
    "    df_quasi_gen.loc[:,col] = pd.cut(df_quasi_gen[col], bins)\n",
    "    return df_quasi_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "r = generalization(df_quasi_copy, \"YoB\", 10, 2019)\n",
    "r = generalization(r, \"nforum_posts\", 10, 470)\n",
    "r = generalization(r, \"nforum_votes\", 10, 640)\n",
    "r = generalization(r, \"nforum_endorsed\", 10, 50)\n",
    "r = generalization(r, \"nforum_threads\", 10, 150)\n",
    "r = generalization(r, \"nforum_comments\", 10, 450)\n",
    "r = generalization(r, \"nforum_pinned\", 10, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5. Compare the number of students who complete and explore the course in the original and in the k-anonymous sets. What does this tell you about the process of de-identification?\n",
    "The process of de-identification adds noise to the dataset, eliminates statistically relevant information, increases the size of the dataset and decreases utility. The completion rates in the k-anonymous sets were <span style=\"color:red\">[get the numbers]</span>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L-Diversity\n",
    "- Used to determine distinguishability among indistunghisable quasi-identifiers but distinguishable sensitive attributes\n",
    "- Sensitive attributes include: grade\n",
    "- Determine level of l-diversity in order to strengthen k-anonymity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lDiverse = r\n",
    "# Add column of sensitive values to dataset that is k-anonymous\n",
    "lDiverse[\"grade\"] = df[\"grade\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lDiverseLevels = lDiverse.groupby(quasi_identifier_labels)[\"grade\"].nunique().reset_index(name = \"l-diversity-grade\")\n",
    "# Find level of diversity (number of unique grades) for each grouping of quasi-identifiers\n",
    "lDiverseLevels[\"l-diversity-grade\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lDiverseLevels[\"l-diversity-grade\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add completed column in order to find completion rate on modified dataset \n",
    "df_quasi[\"completed\"] = df[\"completed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate4Anon_GenBlurSuppress = getAnonCompletionRates(df_quasi, quasi_identifier_labels, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "completionRate5Anon_GenBlurSuppress = getAnonCompletionRates(df_quasi, quasi_identifier_labels, 5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6. What fields in the data set might be considered \"sensitive\" \n",
    "A student's grade may be considered sensitive\n",
    "### In your datasets in 5), what level of l-diversity do the data sets have with respect to these fields? How might you get to a higher level of l-diversity?\n",
    "The level od l-diversity for each set of quasi-identifiers is indicated under the \"l-diversity-grade\" column in lDiverseLevels. Further processing through generalization and blurring would achieve a higher level of l-diversity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
